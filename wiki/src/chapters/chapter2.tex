\chapter{Related Work}
\label{chapter:chapter2}

\section{TPC-W}
\label{sec:tpcw}

The most popular testing and benchmarking solution is TPC-W, which uses a custom-made retail book-store website. It was built to generate massive HTTP load for testing hardware, but it is currently used in academia to test Web hosting systems. Its main advantage is that it generates the workload dynamically, so no database or traffic dumps are used. This feature also allows a more flexible simulation because it has no other restrictions than the user's settings. It contains a workload generator defined as Emulated Browsers which emulate the Internet user behavior. The EBs create the requested number of user sessions and afterwards send request to the Web server, requesting random pages and creating new content. 

Another advantage of TPC-W providing flexibility is the navigational pattern. It is defined by the Customer Behavior Model Graph (CBMG), which is a Markov chain matrix defining all the possible states and transitions from one state to another. The CBMG matrix is defined beforehand and allows the customization of the users' behavior \cite{Menasce}. Each transaction has a certain probability of being chosen, probability which is specified in the matrix. Besides the CBMG, the EBs are defined by the workload intensity specified by the number of EBs and the think time between requests \cite{Pierre}.

There are three categories of user interactions defined by TPC-W, and these are obtained by varying the ratio between read-only requests (browsing activities) and read-write request (buying activities). So the browsing mix contains 95\% of read-only interactions, the shopping mix 80\% of read-only interactions, and the  ordering mix 50\% of  read-only interactions \cite{Amza}.

TPC-W defines two metrics to support the benchmark's measurements. It uses Web Interactions Per Second (WIPS) at a certain scale factor, noted as WIPS@scale-factor. The scales are predefined to the following fixed values: 1,000, 10,000, 100,000, 1,000,000 and 10,000,000, and represent the number of items in the inventory. The purpose of scaling the user number to the number of items was to avoid getting incorrect results for a large number of users and a very small database, but in the same time it limits the user control over the simulation, being one of the system's weaknesses. The other metric includes the cost in its measurements, defined as \$/WIPS \cite{Smith}. It is defined as the ratio between the total price of the System Under Test (SUT) and the WIPS value. SUT includes all the software costs including the maintenance, and the hardware costs like database servers, commerce servers, load balancers, internal networks needed to implement and run the application.

Another weakness is that when an EB ends its session, a new user session is created, in order to maintain the same constant number of users at each moment of the simulation. The interface does not allow to modify the number of users during the simulation. The user sessions are generated from the same machine and are maintained through session cookies \cite{Cain}.

\section{RUBBoS and RUBiS}
\label{sec:rubbos-rubbis}

RUBBoS \cite{RUBBoS-website} is similar to TPC-W, only that it models an online news website, similar to Slashdot. It is able to emulate up to 500,000 users. RUBBoS uses the idea of cache, and the users are expected to access the latest news articles and comments. The old data is moved periodically by a daemon to a database for storage.

RUBiS \cite{RUBiS-website} is a benchmark whose Web server is an auction website, modeled after eBay.com. It defines two types of user behavior, similar to TPC-W, which have different read-write patterns. The browsing mix is made of only read-only interactions and the bidding mix includes 15\% read-write interactions. RUBiS defines a state transition matrix that indicates the probability to go from one state to another, with a random think time between interactions (between 7 seconds and 15 minutes). The load is given by the clients number, but the database contains at least 33,000 items for sale.  RUBiS maintains a history of the auctions, and keeps at most 500,000 auctions in the old-items table.

One of the issues common to previous benchmarks is the fact that they don't use a real-world web application, so their websites lack complex functionalities and advanced security. The second problem is their lack of flexibility and configurability. They offer only a few pre-defined mixes, with fixed read-write ratio, and no possibility to modify them. Besides this, the constant number of user does not match the reality, where great traffic fluctuations could take place. Another issue worth mentioning is the one regarding their system design, which is not distributed. A single machine generating all the requests is not plausible in the real-world.

\section{WikiBench}
\label{sec:wikibench}

WikiBench \cite{RUBBoS-website} is an academic benchmark especially made for testing Web server platforms. It was created to bring realism by using real traffic database dumps from the WikiMedia Foundation. WikiMedia allows to download real traffic logs of requests made to Wikipedia.  WikiBench is different from the previous benchmarks, being centered on processing the WikiMedia traffic traces and transforming them into simulated requests. The main strength of WikiBench is the delivery of a high degree of realism and reproducible results useful when measuring different systems. Despite the fixed traffic behavior, its users have the possibility to lower the intensity of traffic requests, or change the read/write ratio with the cost of altering the original traffic traces.

WikiBench is a very good solution because it simulates Web traffic very realistically and the simulations are reproducible when provided the same Web traffic traces. One major downside of WikiBench is that it requires traffic dumps which take up space and restrict the control over the simulation and user behavior.

WikiBench challenged us to create a solution which is not based on traffic dumps, and which creates its own traffic on the fly, while running the simulation. The user would have flexibility and total control over the simulation. 
