\chapter{Related Work}
\label{chapter:chapter2}

The most popular testing and benchmarking solution is TPC-W, which uses a cusom-made retail book-store website. It was first build to generate massive HTTP load for testing hardware, but it is currently used in academia to test resource provisioning systems. It contains a workload generator defined as Emulated Browsers which emulate the Internet user behavior. The EBs create the requested number of user sessions and afterwards send request to the Web server, requesting random pages and creating new ones. The navigational pattern is defined by the Customer Behavior Model Graph (CBMG) predefined beforehand. It is basically a Markov chain matrix defining all the possible states and transitions from one state to another. Each transaction has a certain probability of being chosen, probability which is specified in the matrix. Besides the CBMG, for the EBs are also defined the workload intensity specified by the EBs number and the think time between requests.

	There are three categories of user interactions defined by TPC-W, and these are obtained by varying the ratio between read-only requests (browsing activities) and read-write request (buying activities). So the browsing mix contains 95\% of read-only interactions, the shopping mix 80\% of read-only interactions, and the  ordering mix 50\% of  read-only interactions.

TPC-W defines two metrics to support the benchmark's measurements. It uses Web Interactions Per Second (WIPS) at a certain scale factor, noted as WIPS@scale-factor. The scales are predefined to the following fixed values: 1,000, 10,000, 100,000, 1,000,000 and 10,000,000 books or product items. The other metric also includes the cost in its measurements, defined as \$/WIPS. This is the ratio between the total price of the Web servers, database servers, commerce servers, load balancers, networks, and corresponding software, which are needed to implement the application being emulated, and the WIPS value. 

One downside is that when an EB ends its session, a new user session is created, in order to maintain a constant number of users at each moment of the simulation. The user sessions are generated from the same machine and are maintained through session cookies.

RUBBoS is similar to TPC-W, only that it models an online news website, similar to Slashdot. It is able to emulate up to 500,000 users. RUBBoS uses the idea of cache, and the users are expected to access the latest news articles and comments. The old data is moved periodically by a daemon to a database for storage.

RUBiS is a benchmark whose WebServer is an auction website, modeled after eBay.com. It defines two types of user behaviors, similar to TPC-W, which have different read-write patterns. The browsing mix is made of only read-only interactions and the bidding mix includes 15\% read-write interactions. RUBiS defines a state transition matrix that indicates the probability to go from one state to another, with a random think time between interactions (between 7 seconds and 15 minutes). The load is given by the clients number, but the database contains at least 33,000 items for sale.  RUBiS maintains a history of the auctions, and keeps at most 500,000 auctions in the old-items table.

One of the issues common to previous benchmarks is the fact that they don't use a real-world web application, so their websites lack complex functionalities and advanced security. The second problem is their lack of flexibility and configurability. They offer only a few pre-defined mixes, with fixed read-write ratio, with no possibility to modify them. Besides this, the constant number of user does not match the reality, where great traffic fluctuations could take place. Another issue worth mentioning is the one regarding their system design, which is not distributed. A single machine generating all the requests is not plausible in the real-world.

WikiBench is an academic benchmark especially made for testing Web server platforms. It was created to bring realism by using real traffic database dumps from the WikiMedia Foundation. WikiMedia allows to download real traffic logs of requests made to Wikipedia.  WikiBench is different from the previous benchmarks, being centered on processing the WikiMedia traffic traces and transforming them into simulated requests. The benchmark offers a high degree of realism, and its results are reproducible. Despite the fixed traffic behaviour, its users have the possibility to lower the intensity of traffic requests, or change the read/write ratio with the cost of altering the original traffic traces.

WikiBench is a very good solution, which simulates Web traffic very realistic. This application challenged us to create a solution which is not based on traffic dumps, and which creates its own traffic on the fly, while running the simulation. The user would have flexibility and total control over the simulation.
