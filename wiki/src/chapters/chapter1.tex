\chapter{Introduction}
\label{chapter:chapter1}

Current IT trends are moving towards fully developed Internet applications and storage services. Lightweight Internet services like e-mail, social networking and news and blog feeds are also very popular. The information demand is getting very high, so the information availability is important, as well as a high level of reliability. For offering such Internet applications and storage services there is an obvious need of a strong infrastructure support which needs extensive testing beforehand. Academic researchers and industry developers need benchmarks to test their databases, load balancers, application servers, cloud computing platforms, or other Web hosting platforms. They do not only need massive load generators, but also realistic web traffic, which emulates real workload as precisely as possible. This is done by analyzing and modeling user behavior. Benchmarks offer an idea of how the resource provisioning system would react in extreme cases like overload, or flash crowds. Besides this, benchmarks offer a reproducible and comparable simulation needed for comparing different systems, or even the same updated system.

Benchmarks are used for various types of testing, one of them being functional testing, where the requirements and the system's functionalities are tested. Non-functional testing includes performance testing, which measures the response time, the scalability and reliability of the system. There is also load testing, which checks if the system is scalable and supports the demand of a large number of users. Stress testing checks the system's reliability, availability and error handling.

Benchmarks generate web traffic for stressing various components of the hosting system under test. The Web server is the main component of the Web hosting system, being the contact point where all requests are sent. This is why Web servers is the most tested component. Most systems also include a database server, which is tested through intensive read/write requests of either static or dynamic data.  Some systems might also contain a caching server, an image server, or a multimedia server, depending on what is their purpose, which also need to be put under test.

In the last years, as soon as the demand for such benchmarks increased, a few benchmarks emerged and are still used up to this moment. Some of them are very popular, like TPC-W \cite{TPCW-website}, which is viewed as an industry standard for testing hosting systems, despite the fact that it is officially outdated. Although it was originally built for testing hardware by generating massive load, nowadays its modified versions are still used in academia for testing resource provisioning systems.  TPC-W simulates a retail book-store website and emulates thousands of browsers. Similarly, RUBBoS \cite{RUBBoS-website} and RUBBiS \cite{RUBiS-website} model a bulletin board website, and an e-commerce website. These applications are centered on simulating a massive number of HTTP requests.

The main problems with the previous benchmarks is that they are very limited. They do not represent realistic Web sites and do not offer very realistic simulations of web traffic. They offer little control over the simulation, having pre-defined scales. These are very useful to compare other systems, or to repeat an experiment, but do not offer flexibility. The websites used by them are custom made for the benchmarks, and are not designed for real usage, and therefore are not very convincing.

A new generation of Web application benchmarks is necessary. One benchamark that emerged lately is WikiBench. It is an academic  benchmark, made for testing server platforms, and which uses real traffic by manipulating real traffic database dumps. Its main advantage is that it offers a high degree of realism and its results are reproducible. Despite the fixed traffic traces, the traffic characteristics can be modified for the simulation, lowering the realism of the simulation. One problem is that WikiBench is not flexible and it does not offer a lot of control over the simulation characteristics.

We have designed and developed WordPressBench in order to surpass some of the problems of previously described benchmarks. It aims at bringing flexible user controls and more realistic Web traffic simulation. It generates the traffic dynamically, and it is not based on old traffic dumps. WordPressBench offers more control and flexibility, making the simulation process more precise and easier to adapt to user's simulation requirements. The users can simulate better the desired test cases. This thesis presents the challenges, design and implementation of WordPressBench.

WordPressBench is a Web-hosting benchmark for testing various Web-server platforms by emulating real-user behavior.  Its web-servers run WordPress \cite{Wordpress-website}, a real website, used by a large number of Internet users. The system is designed with a distributed worker configuration, having a master-slave architecture. The workers are the ones generating the workload towards the Wordpress Web site placed on the system under test. The users are emulated better, being placed on multiple servers, and the number of emulated users can be modified while running the simulation. The benchmark does not use traffic dumps and generates all the traffic on the fly, so no additional databases or storage is needed.

The remainder of the document is organized as follows. 

\labelindexref{Section}{chapter:chapter2} describes the existing benchmarks and their issues. \labelindexref{Section}{chapter:chapter3} offers an overview of WordPressBench with the challenges we met, scope and requirements. \labelindexref{Section}{chapter:chapter4} offers a more detailed description of each component of  WordPressBench. \labelindexref{Section}{chapter:chapter5} describes the evaluation process of the system. \labelindexref{Section}{chapter:chapter6} offers a few ideas for future extensions after which the conclusion drawn.
